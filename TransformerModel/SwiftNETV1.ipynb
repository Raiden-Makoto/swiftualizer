{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDJRmup1D1sikZuuirJ9LR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raiden-Makoto/swiftualizer/blob/main/TransformerModel/SwiftNETV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SwiftNET:\n",
        "**Keras + Tensorflow implementation of WaveNET specifically trained to generate pop songs in the style of Taylor Swift**"
      ],
      "metadata": {
        "id": "vs5PxgsfM0HB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "q0PcEGGOHR1S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.data as tf_data\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.initializers import GlorotUniform, Zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Operation for the main **SwiftNET** Model\n",
        "Code is sourced from [here](https://github.com/kokeshing/WaveNet-tf2/blob/master/model/module.py) but modified to use `Keras 3`."
      ],
      "metadata": {
        "id": "S4UF8T3jH0_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A causal convolution layer is a type of 1D convolution designed for sequential data where the output at time step $t$ depends only on inputs from time steps\n",
        "$ \\leq t$. This structure ensures that there is no \"leakage\" of future information into the past, making it useful for autoregressive models like WaveNet and time-series forecasting."
      ],
      "metadata": {
        "id": "SflQlPr9KctJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalConvolutionLayer(layers.Conv1D):\n",
        "    def __init__(\n",
        "            self,\n",
        "            filters,\n",
        "            kernel_size,\n",
        "            strides=1,\n",
        "            padding='causal',\n",
        "            dilation_rate=1,\n",
        "            residual_channels=None,\n",
        "            *args,\n",
        "            **kwargs\n",
        "        ):\n",
        "        super().__init__(\n",
        "            filters,\n",
        "            kernel_size,\n",
        "            strides=strides,\n",
        "            padding=padding,\n",
        "            dilation_rate=dilation_rate\n",
        "        )\n",
        "        self.k = kernel_size\n",
        "        self.d = dilation_rate\n",
        "        if kernel_size > 1:\n",
        "            self.queue_len = kernel_size + (kernel_size - 1) * (dilation_rate - 1)\n",
        "            self.queue_dim = residual_channels\n",
        "            self.init_queue()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super().build(input_shape)\n",
        "        self.linearized_weights = ops.cast(\n",
        "            ops.reshape(self.kernel, [-1, self.filters]),\n",
        "            dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, is_synthesis=False):\n",
        "        if not is_synthesis: return super().call(inputs)\n",
        "        if self.k > 1:\n",
        "            self.queue = self.queue[:, 1:, :]\n",
        "            self.queue = ops.concatenate(\n",
        "                [self.queue, ops.expand_dims(inputs[:, -1, :], axis=1)],\n",
        "                axis=1\n",
        "            )\n",
        "            if self.d > 1: inputs = self.queue[:, 0::self.d, :]\n",
        "            else: inputs = self.queue\n",
        "        outputs = ops.matmul(ops.reshape(inputs, [1, -1]), self.linearized_weights)\n",
        "        outputs = keras.backend.bias_add(outputs, self.bias)\n",
        "        return tf.reshape(outputs, [-1, 1, self.filters])\n",
        "\n",
        "    def init_queue(self):\n",
        "        self.queue = ops.zeros([1, self.queue_len, self.queue_dim], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "CRb6GmCeHiwD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConv1DGLU(keras.Model):\n",
        "    \"\"\"conv1d + GLU => add condition => residual add + skip connection\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            residual_channels,\n",
        "            gate_channels,\n",
        "            kernel_size,\n",
        "            skip_out_channels=None,\n",
        "            dilation_rate=1,\n",
        "            **kwargs\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.residual_channels = residual_channels\n",
        "        if skip_out_channels is None: skip_out_channels = residual_channels\n",
        "\n",
        "        self.dilated_conv = CausalConvolutionLayer(\n",
        "            gate_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            padding='causal',\n",
        "            dilation_rate=dilation_rate,\n",
        "            residual_channels=residual_channels\n",
        "        )\n",
        "        self.conv_c = CausalConvolutionLayer(\n",
        "            gate_channels,\n",
        "            kernel_size=1,\n",
        "            padding='causal'\n",
        "        )\n",
        "        self.conv_skip = CausalConvolutionLayer(\n",
        "            skip_out_channels,\n",
        "            kernel_size=1,\n",
        "            padding='causal'\n",
        "        )\n",
        "        self.conv_out = CausalConvolutionLayer(\n",
        "            residual_channels,\n",
        "            kernel_size=1,\n",
        "            padding='causal'\n",
        "        )\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs, c):\n",
        "        x = self.dilated_conv(inputs)\n",
        "        x_tanh, x_sigmoid = ops.split(x, indices_or_sections=2, axis=2)\n",
        "        c = self.conv_c(c)\n",
        "        c_tanh, c_sigmoid = tf.split(c, indices_or_sections=2, axis=2)\n",
        "\n",
        "        x_tanh, x_sigmoid = x_tanh + c_tanh, x_sigmoid + c_sigmoid\n",
        "        x = tf.nn.tanh(x_tanh) * tf.nn.sigmoid(x_sigmoid)\n",
        "\n",
        "        s = self.conv_skip(x)\n",
        "        x = self.conv_out(x)\n",
        "\n",
        "        x = x + inputs\n",
        "\n",
        "        return x, s\n",
        "\n",
        "    def init_queue(self):\n",
        "        self.dilated_conv.init_queue()\n",
        "\n",
        "    def synthesis_feed(self, inputs, c):\n",
        "        x = self.dilated_conv(inputs, is_synthesis=True)\n",
        "        x_tanh, x_sigmoid = tf.split(x, num_or_size_splits=2, axis=2)\n",
        "\n",
        "        c = self.conv_c(c, is_synthesis=True)\n",
        "        c_tanh, c_sigmoid = tf.split(c, num_or_size_splits=2, axis=2)\n",
        "\n",
        "        x_tanh, x_sigmoid = x_tanh + c_tanh, x_sigmoid + c_sigmoid\n",
        "        x = tf.nn.tanh(x_tanh) *keras.activations.sigmoid(x_sigmoid)\n",
        "        s = self.conv_skip(x, is_synthesis=True)\n",
        "        x = self.conv_out(x, is_synthesis=True)\n",
        "        x = x + inputs\n",
        "        return x, s"
      ],
      "metadata": {
        "id": "q8VO2HqdBQZE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create UpSampling Layers"
      ],
      "metadata": {
        "id": "TgRHOTTfDKV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In WaveNet, upsampling layers are be applied at the final output layer to expand or refine the predictions (e.g., generating high-frequency audio details)."
      ],
      "metadata": {
        "id": "LsLIpT-9DxfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UpsampleConv(tf.keras.Model):\n",
        "    def __init__(self, rate, **kwargs):\n",
        "        super().__init__()\n",
        "        self.upsampling = layers.UpSampling2D(\n",
        "            size=(1, rate),\n",
        "            interpolation='nearest'\n",
        "        )\n",
        "        self.conv = layers.Conv2D(\n",
        "            filters=1,\n",
        "            kernel_size=(1, rate * 2 + 1),\n",
        "            padding='same',\n",
        "            use_bias=False,\n",
        "            kernel_initializer=tf.constant_initializer(1. / (rate * 2 + 1))\n",
        "        )\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        return self.conv(self.upsampling(x))"
      ],
      "metadata": {
        "id": "6LrHtTTnDnMz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpsampleNetwork(tf.keras.Model):\n",
        "    def __init__(self, upsample_scales, **kwargs):\n",
        "        super().__init__()\n",
        "        self.upsample_layers = [UpsampleConv(scale) for scale in upsample_scales]\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, feat):\n",
        "        for layer in self.upsample_layers:\n",
        "            feat = layer(feat)\n",
        "        return feat"
      ],
      "metadata": {
        "id": "HAj2vV7LEfkr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the SwiftNET Model"
      ],
      "metadata": {
        "id": "rQWv4zykN9Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O3U8O39k3_U7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}