{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCe/OdrgY//n/PhGNTirEB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raiden-Makoto/swiftualizer/blob/main/TransformerModel/SwiftNETV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SwiftNET:\n",
        "**Keras + Tensorflow implementation of WaveNET specifically trained to generate pop songs in the style of Taylor Swift**"
      ],
      "metadata": {
        "id": "vs5PxgsfM0HB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q0PcEGGOHR1S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.data as tf_data\n",
        "import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Operations for the main **SwiftNET** Model"
      ],
      "metadata": {
        "id": "S4UF8T3jH0_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A causal convolution layer is a type of 1D convolution designed for sequential data where the output at time step $t$ depends only on inputs from time steps\n",
        "$ \\leq t$. This structure ensures that there is no \"leakage\" of future information into the past, making it useful for autoregressive models like WaveNet and time-series forecasting."
      ],
      "metadata": {
        "id": "SflQlPr9KctJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CausalConvolutionLayer(value, filters, kernel_size, dilation, name='causal_conv'):\n",
        "    with tf.name_scope(name):\n",
        "        CausalConv = layers.Conv1D(\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            dilation_rate=dilation,\n",
        "            padding='causal',\n",
        "        )\n",
        "        return CausalConv(value)"
      ],
      "metadata": {
        "id": "CRb6GmCeHiwD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Companding (short for compressing + expanding) is a technique used in signal processing to reduce the dynamic range of a signal before quantization and restore it afterward. It helps to improve signal quality, reduce quantization noise, and optimize storage or transmission efficiencyâ€”especially in audio, speech processing, and telecommunications.\n",
        "\n",
        "The mu-law transformation is a nonlinear companding algorithm used in digital audio processing and speech compression. It reduces the dynamic range of an audio signal, improving quantization at lower amplitudes while preserving detail in louder signals."
      ],
      "metadata": {
        "id": "k02R37bTLcDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MuLawEncode(audio, num_quantization_channels):\n",
        "    with tf.name_scope(\"MuLawEncode\"):\n",
        "        mu = tf.cast(num_quantization_channels - 1, dtype=tf.float32)\n",
        "        safe_audio_abs = tf.minimum(tf.abs(audio), 1.0)\n",
        "        magnitude = tf.math.log1p(mu * safe_audio_abs) / tf.math.log1p(mu)\n",
        "        signal = tf.sign(audio) * magnitude\n",
        "        encoded = tf.cast((signal + 1) / 2 * mu + 0.5, dtype=tf.int32)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "NgdM0nEOKU1v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create `tf.Variable`s"
      ],
      "metadata": {
        "id": "eXc7uZJ2LycZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_variable(name, shape):\n",
        "    '''Creates a convolution filter variable with Xavier (Glorot) initialization.'''\n",
        "    with tf.name_scope(name):\n",
        "        initializer = tf.keras.initializers.GlorotUniform()  # Xavier initialization\n",
        "        variable = tf.Variable(initializer(shape), name=name, trainable=True)\n",
        "    return variable"
      ],
      "metadata": {
        "id": "RRldEl79LlTs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_table(name, shape):\n",
        "    '''Creates an embedding table, initializing it as an identity matrix if square.'''\n",
        "    with tf.name_scope(name):\n",
        "        if shape[0] == shape[1]:\n",
        "            initial_val = np.identity(n=shape[0], dtype=np.float32)\n",
        "            return tf.Variable(initial_val, name=name, trainable=True)\n",
        "        else:\n",
        "            return create_variable(name, shape)"
      ],
      "metadata": {
        "id": "HHbM1ryVNHhK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bias_variable(name, shape):\n",
        "    '''Create a bias variable with the specified name and shape and initialize\n",
        "    it to zero.'''\n",
        "    initializer = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
        "    return tf.Variable(initializer(shape=shape), name)"
      ],
      "metadata": {
        "id": "0rFDGHx3NrHf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the SwiftNET Model"
      ],
      "metadata": {
        "id": "rQWv4zykN9Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SwiftNet(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        batch_size,\n",
        "        dilations,\n",
        "        filter_width,\n",
        "        residual_channels,\n",
        "        dilation_channels,\n",
        "        skip_channels,\n",
        "        quantization_channels=2**8,\n",
        "        use_biases=False,\n",
        "        scalar_input=False,\n",
        "        initial_filter_width=32,\n",
        "        histograms=False,\n",
        "        global_condition_channels=None,\n",
        "        global_condition_cardinality=None\n",
        "    ):\n",
        "        super(SwiftNet, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.dilations = dilations\n",
        "        self.filter_width = filter_width\n",
        "        self.residual_channels = residual_channels\n",
        "        self.dilation_channels = dilation_channels\n",
        "        self.quantization_channels = quantization_channels\n",
        "        self.use_biases = use_biases\n",
        "        self.skip_channels = skip_channels\n",
        "        self.scalar_input = scalar_input\n",
        "        self.initial_filter_width = initial_filter_width\n",
        "        self.histograms = histograms\n",
        "        self.global_condition_channels = global_condition_channels\n",
        "        self.global_condition_cardinality = global_condition_cardinality\n",
        "\n",
        "        self.receptive_field = self.calculate_receptive_field(\n",
        "            self.filter_width,\n",
        "            self.dilations,\n",
        "            self.scalar_input,\n",
        "            self.initial_filter_width\n",
        "        )\n",
        "        self.variables = self._create_variables()\n",
        "\n",
        "    def calculate_receptive_field(self, filter_width, dilations, scalar_input, initial_filter_width):\n",
        "        receptive_field = (filter_width - 1) * sum(dilations) + 1\n",
        "        if scalar_input: receptive_field += initial_filter_width - 1\n",
        "        else: receptive_field += filter_width - 1\n",
        "        return receptive_field\n",
        "\n",
        "    def _create_variables(self):\n",
        "        variables = {}"
      ],
      "metadata": {
        "id": "5YJwX2zPN5h6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PcqyeQv8P58X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}